# å•å…ƒ 1: æ‰©æ•£æ¨¡å‹ç®€ä»‹

æ¬¢è¿æ¥åˆ°Hugging Faceæ‰©æ•£æ¨¡å‹è¯¾ç¨‹ç¬¬ä¸€å•å…ƒï¼åœ¨æœ¬å•å…ƒä¸­ï¼Œæ‚¨å°†å­¦ä¹ æœ‰å…³æ‰©æ•£æ¨¡å‹å¦‚ä½•å·¥ä½œçš„åŸºç¡€çŸ¥è¯†ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨ğŸ¤— diffusersåº“ã€‚

## å¼€å§‹æœ¬å•å…ƒ :rocket:

ä»¥ä¸‹æ˜¯æœ¬å•å…ƒçš„å­¦ä¹ æ­¥éª¤:

- è¯·ç¡®ä¿ä½ å·²ç»[æ³¨å†Œäº†è¯¥è¯¾ç¨‹](https://huggingface.us17.list-manage.com/subscribe?u=7f57e683fa28b51bfc493d048&id=ef963b4162)ã€‚è¿™æ ·å½“æœ‰æ–°è¯¾ç¨‹ææ–™å‘å¸ƒçš„æ—¶å€™ä½ å°±ä¼šæ”¶åˆ°é€šçŸ¥
- é€šè¯»ä¸‹é¢çš„ä»‹ç»ææ–™ä»¥åŠä»»ä½•ä½ æ„Ÿå…´è¶£çš„å…¶ä»–èµ„æº
- æŸ¥çœ‹ä¸‹é¢çš„ _**æ‰©æ•£å™¨ç®€ä»‹**_ ç¬”è®°æœ¬ï¼Œä»¥ä½¿ç”¨diffuersåº“å°†ç†è®ºåº”ç”¨åˆ°å®è·µä¸­
- ä½¿ç”¨notebookæˆ–é“¾æ¥çš„è®­ç»ƒè„šæœ¬æ¥è®­ç»ƒå’Œåˆ†äº«æ‚¨è‡ªå·±çš„æ‰©æ•£æ¨¡å‹
- (å¯é€‰) å¦‚æœæ‚¨æœ‰å…´è¶£çœ‹åˆ°ä¸€ä¸ªæç®€çš„ä»å¤´å¼€å§‹çš„é¡¹ç›®å®ç°ï¼Œå¹¶æ¢ç´¢æ‰€æ¶‰åŠçš„ä¸åŒè®¾è®¡å†³ç­–ï¼Œæ‚¨å¯ä»¥æ·±å…¥ç ”ç©¶ _**ä»å¤´å¼€å§‹ä¸€ä¸ªæ‰©æ•£æ¨¡å‹**_ notebookã€‚


:loudspeaker: è¯·ä¸è¦å¿˜äº†åŠ å…¥æˆ‘ä»¬çš„é¢‘é“ [Discord](https://huggingface.co/join/discord), ä½ å¯ä»¥åœ¨`#diffusion-models-class` é¢‘é“æ¥è®¨è®ºè¯¾ç¨‹å†…å®¹ä»¥åŠåˆ†äº«æ‚¨çš„ä½œå“ã€‚
 
## ä»€ä¹ˆæ˜¯æ‰©æ•£æ¨¡å‹?

æ‰©æ•£æ¨¡å‹æ˜¯â€œç”Ÿæˆæ¨¡å‹â€ç®—æ³•å®¶æ—çš„æ–°æˆå‘˜é€šè¿‡å­¦ä¹ ç»™å®šçš„è®­ç»ƒæ ·æœ¬ï¼Œç”Ÿæˆæ¨¡å‹å¯ä»¥å­¦ä¼šå¦‚ä½•**ç”Ÿæˆ**æ•°æ®ï¼Œæ¯”å¦‚ç”Ÿæˆå›¾ç‰‡æˆ–è€…å£°éŸ³ã€‚ä¸€ä¸ªå¥½çš„ç”Ÿæˆæ¨¡å‹èƒ½ç”Ÿæˆä¸€ç»„**æ ·å¼ä¸åŒ**çš„è¾“å‡ºã€‚è¿™äº›è¾“å‡ºä¼šä¸è®­ç»ƒæ•°æ®ç›¸ä¼¼ï¼Œä½†ä¸æ˜¯ä¸€æ¨¡ä¸€æ ·çš„å‰¯æœ¬ã€‚æ‰©æ•£æ¨¡å‹å¦‚ä½•å®ç°è¿™ä¸€ç‚¹ï¼Ÿä¸ºäº†ä¾¿äºè¯´æ˜ï¼Œè®©æˆ‘ä»¬å…ˆçœ‹çœ‹å›¾åƒç”Ÿæˆçš„æ¡ˆä¾‹ã€‚

<p align="center">
    <img src="https://user-images.githubusercontent.com/10695622/174349667-04e9e485-793b-429a-affe-096e8199ad5b.png" width="800"/>
    <br>
    <em> å›¾ç‰‡æ¥æºäºDDPM paper (https://arxiv.org/abs/2006.11239). </em>
<p>

æ‰©æ•£æ¨¡å‹æˆåŠŸçš„ç§˜è¯€åœ¨äºæ‰©æ•£è¿‡ç¨‹çš„è¿­ä»£æœ¬è´¨ã€‚æœ€å…ˆç”Ÿæˆçš„åªæ˜¯ä¸€ç»„éšæœºå™ªå£°ï¼Œä½†ç»è¿‡è‹¥å¹²æ­¥éª¤é€æ¸æ”¹å–„ï¼Œæœ‰æ„ä¹‰çš„å›¾åƒå°†æœ€ç»ˆä¼šå‡ºç°ã€‚åœ¨æ¯ä¸€æ­¥ä¸­ï¼Œæ¨¡å‹éƒ½ä¼šä¼°è®¡å¦‚ä½•ä»å½“å‰çš„è¾“å…¥ç”Ÿæˆå®Œå…¨å»å™ªçš„ç»“æœã€‚å› ä¸ºæˆ‘ä»¬åœ¨æ¯ä¸€æ­¥éƒ½åªåšäº†ä¸€ä¸ªå°å°çš„å˜åŠ¨ï¼Œæ‰€ä»¥åœ¨æ—©æœŸé˜¶æ®µï¼ˆé¢„æµ‹æœ€ç»ˆè¾“å‡ºå®é™…ä¸Šéå¸¸å›°éš¾ï¼‰ï¼Œè¿™ä¸ªä¼°è®¡ä¸­çš„ä»»ä½•erroréƒ½å¯ä»¥åœ¨ä»¥åçš„æ›´æ–°ä¸­å¾—åˆ°çº æ­£ã€‚

ä¸å…¶ä»–ç±»å‹çš„ç”Ÿæˆæ¨¡å‹ç›¸æ¯”ï¼Œè®­ç»ƒæ‰©æ•£æ¨¡å‹ç›¸å¯¹è¾ƒä¸ºå®¹æ˜“ã€‚æˆ‘ä»¬åªéœ€è¦é‡å¤ä»¥ä¸‹æ­¥éª¤å³å¯ï¼š
1) Load in some images from the training data
2) Add noise, in different amounts. Remember, we want the model to do a good job estimating how to 'fix' (denoise) both extremely noisy images and images that are close to perfect.
3) Feed the noisy versions of the inputs into the model
4) Evaluate how well the model does at denoising these inputs
5) Use this information to update the model weights

1) ä»è®­ç»ƒæ•°æ®ä¸­åŠ è½½ä¸€äº›å›¾åƒ
2) æ·»åŠ ä¸åŒçº§åˆ«çš„å™ªå£°ã€‚è¯·è®°ä½ï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹åœ¨é¢å¯¹æ·»åŠ äº†æç«¯å™ªå£°å’Œå‡ ä¹æ²¡æœ‰æ·»åŠ å™ªå£°çš„å¸¦å™ªå›¾åƒæ—¶ï¼Œéƒ½èƒ½å¤Ÿå¾ˆå¥½åœ°ä¼°è®¡å¦‚ä½•â€œä¿®å¤â€ï¼ˆå»å™ªï¼‰ã€‚
3) å°†å¸¦å™ªè¾“å…¥é€å…¥æ¨¡å‹ä¸­
4) è¯„ä¼°æ¨¡å‹å¯¹è¿™äº›è¾“å…¥è¿›è¡Œå»å™ªçš„æ•ˆæœ
5) ä½¿ç”¨æ­¤ä¿¡æ¯æ›´æ–°æ¨¡å‹æƒé‡

To generate new images with a trained model, we begin with a completely random input and repeatedly feed it through the model, updating it each time by a small amount based on the model prediction. As we'll see, there are a number of sampling methods that try to streamline this process so that we can generate good images with as few steps as possible.

We will show each of these steps in detail in the hands-on notebooks here in unit 1. In unit 2, we will look at how this process can be modified to add additional control over the model outputs through extra conditioning (such as a class label) or with techniques such as guidance. And units 3 and 4 will explore an extremely powerful diffusion model called Stable Diffusion, which can generate images given text descriptions.  

## Hands-On Notebooks

At this point, you know enough to get started with the accompanying notebooks! The two notebooks here come at the same idea in different ways. 
 
| Chapter                                     | Colab                                                                                                                                                                                               | Kaggle                                                                                                                                                                                                   | Gradient                                                                                                                                                                               | Studio Lab                                                                                                                                                                                                   |
|:--------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Introduction to Diffusers                                | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/diffusion-models-class/blob/main/unit1/01_introduction_to_diffusers.ipynb)              | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/huggingface/diffusion-models-class/blob/main/unit1/01_introduction_to_diffusers.ipynb)              | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/huggingface/diffusion-models-class/blob/main/unit1/01_introduction_to_diffusers.ipynb)              | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/diffusion-models-class/blob/main/unit1/01_introduction_to_diffusers.ipynb)              |
| Diffusion Models from Scratch                                | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/diffusion-models-class/blob/main/unit1/02_diffusion_models_from_scratch.ipynb)              | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/huggingface/diffusion-models-class/blob/main/unit1/02_diffusion_models_from_scratch.ipynb)              | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/huggingface/diffusion-models-class/blob/main/unit1/02_diffusion_models_from_scratch.ipynb)              | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/diffusion-models-class/blob/main/unit1/02_diffusion_models_from_scratch.ipynb)              |

In _**Introduction to Diffusers**_, we show the different steps described above using building blocks from the diffusers library. You'll quickly see how to create, train and sample your own diffusion models on whatever data you choose. By the end of the notebook, you'll be able to read and modify the example training script to train diffusion models and share them with the world! This notebook also introduces the main exercise associated with this unit, where we will collectively attempt to figure out good 'training recipes' for diffusion models at different scales - see the next section for more info.

In _**Diffusion Models from Scratch**_ we show those same steps (adding noise to data, creating a model, training and sampling) but implemented from scratch in PyTorch as simply as possible. Then we compare this 'toy example' with the diffusers version, noting how the two differ and where improvements have been made. The goal here is to gain familiarity with the different components and the design decisions that go into them, so that when you look at a new implementation you can quickly identify the key ideas.

## Project Time

Now that you've got the basics down, have a go at training one or more diffusion models! Some suggestions are included at the end of the _**Introduction to Diffusers**_ notebook. Make sure to share your results, training recipes and findings with the community so that we can collectively figure out the best ways to train these models.

## Some Additional Resources
 
[The Annotated Diffusion Model](https://huggingface.co/blog/annotated-diffusion) is a very in-depth walk-through of the code and theory behind DDPMs with 
 maths and code showing all the different components. It also links to a number of papers for further reading.
 
Hugging Face documentation on [Unconditional Image-Generation
](https://huggingface.co/docs/diffusers/training/unconditional_training) for some examples of how to train diffusion models using the official training example script, including code showing how to create your own dataset. 

AI Coffee Break video on Diffusion Models: https://www.youtube.com/watch?v=344w5h24-h8

Yannic Kilcher Video on DDPMs: https://www.youtube.com/watch?v=W-O7AZNzbzQ

ä½ æ‰¾åˆ°äº†æ›´å¤šå¾ˆæ£’çš„èµ„æºï¼Ÿè¯·åŠ¡å¿…è®©æˆ‘ä»¬çŸ¥é“ï¼Œæˆ‘ä»¬ä¼šå°†ä»–ä»¬æ·»åŠ åˆ°æ­¤åˆ—è¡¨ä¸­ã€‚
